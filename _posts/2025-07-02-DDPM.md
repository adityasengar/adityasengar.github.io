---
layout: post
title: "DDPM"
hidden: true
date: 2025-07-02
---
# From Noise to Art: A Deep Dive into Diffusion Models and the EDM Revolution

# From Noise to Art: A Deep Dive into Diffusion Models and the EDM Revolution
*July 2, 2025*

If you've been anywhere near the AI space recently, you've seen the stunning images produced by models like DALL-E 3, Midjourney, and Stable Diffusion. The technology behind many of these state-of-the-art generators is a class of models known as **Diffusion Models**.

At first glance, their inner workings seem almost magical. They start with pure random noise and meticulously sculpt it into a coherent, often beautiful, image. But how? This post offers a comprehensive comparison of where these models started with **DDPM** (Denoising Diffusion Probabilistic Models) and where they are now, thanks to the game-changing **EDM** (Elucidating Diffusion Models) framework.

We will break down their core components—the forward and reverse processes—comparing them mathematically, logically, and in terms of the parameters you control.

---

## The Forward Process: A Tale of Two Schedules

The forward process is the foundation of diffusion: methodically turning a clean image into pure noise. While the goal is the same, the DDPM and EDM approaches parameterize this journey very differently.

### The DDPM Approach (Discrete Time)

DDPM defines the process over a large, fixed number of discrete timesteps, `T` (e.g., 1000).

* **Logic & Math:** At each step `t`, a small amount of Gaussian noise is added according to a variance schedule `βt`. `βt` increases over time, so more noise is added at later steps.

    The single-step transition is:
    $$
    x_t = \sqrt{1 - \beta_t} \cdot x_{t-1} + \sqrt{\beta_t} \cdot \epsilon_{t-1} \quad \text{where} \quad \epsilon \sim \mathcal{N}(0, I)
    $$
    The key insight is that this can be expressed in a closed form, allowing us to jump to any timestep `t` directly from the original image `x₀`. Let $\alpha_t = 1 - \beta_t$ and $\bar{\alpha}_t = \prod_{i=1}^{t} \alpha_i$:
    $$
    x_t = \sqrt{\bar{\alpha}_t} \cdot x_0 + \sqrt{1 - \bar{\alpha}_t} \cdot \epsilon
    $$

* **Parameters:** You control this rigid process with a few knobs:
    * `T`: The total number of timesteps (e.g., 1000).
    * `beta_start`, `beta_end`: Define the range of the noise variance.
    * `scheduler_type`: Defines how `βt` progresses from start to end (e.g., `linear`, `cosine`).

### The EDM Approach (Continuous Time)

EDM generalizes this process by thinking in terms of a continuous noise level, `σ`, instead of discrete steps.

* **Logic & Math:** Instead of a fixed schedule of `β`'s, EDM defines a continuous function `σ(t)` that maps time `t` (from 0 to 1) to a noise magnitude. The model is trained on a distribution of `σ` values, making it independent of any fixed number of steps.

* **Parameters:** The controls are more abstract and powerful:
    * `σ_min`, `σ_max`: The minimum and maximum noise levels (e.g., 0.002 to 80.0).
    * `ρ` (rho): A parameter that shapes the distribution of noise levels during training and sampling. A higher `ρ` concentrates samples/steps at lower noise levels, which is crucial for detail.

| Forward Process | DDPM (Discrete) | EDM (Continuous) |
| :--- | :--- | :--- |
| **Logic** | Fixed `T` steps, adding scheduled noise. | A continuous path from high to low noise. |
| **Math** | Parameterized by `βt`. | Parameterized by `σ(t)`. |
| **Parameters** | `T`, `beta_start`, `beta_end`, `scheduler`. | `σ_min`, `σ_max`, `ρ`. |

---

## The Reverse Process: From Slow Guesswork to Precision Engineering

The reverse process is where the magic happens—learning to turn noise back into an image. Here, the differences between DDPM and EDM are even more stark, spanning both training and sampling.

### The DDPM Approach (Stochastic Ancestral Sampling)

* **Training:** The model `ϵ_θ(x_t, t)` is a U-Net trained to predict the noise `ϵ` that was added to create `x_t`. The objective is a simple Mean Squared Error loss:
    $$
    \mathcal{L}_{\text{simple}} = \mathbb{E}_{t, x_0, \epsilon} \left[ || \epsilon - \epsilon_\theta(x_t, t) ||^2 \right]
    $$

* **Sampling:** To generate an image, DDPM uses an **ancestral sampler**. It iterates backwards from `T` down to 1. At each step `t`, it uses the model's noise prediction to estimate the previous, cleaner image `x_{t-1}` and then adds a small amount of random noise back in. This makes the process **stochastic** and slow. The update rule looks something like this:
    $$
    x_{t-1} = \frac{1}{\sqrt{\alpha_t}} \left( x_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \epsilon_\theta(x_t, t) \right) + \sigma_t z \quad \text{where} \quad z \sim \mathcal{N}(0, I)
    $$
    The key is the `+ σ_t z` term, which injects randomness at every step.

### The EDM Approach (ODE Solving & Preconditioning)

* **Training:** The core loss function is fundamentally the same (an MSE on noise/score), but the model itself is far more sophisticated. EDM introduces **network preconditioning**. The final denoiser `D(x; σ)` is a wrapper around the U-Net `F_θ`:
    ```
    D(x; σ) = c_skip(σ) * x + c_out(σ) * F_θ(c_in(σ) * x; σ)
    ```
    This structure normalizes the network's inputs and outputs based on the noise level `σ`, making the learning task much more stable and effective.

* **Sampling:** EDM reframes sampling as solving an Ordinary Differential Equation (ODE). This allows the use of more advanced numerical solvers. The default is the **2nd-order Heun method**, which is **deterministic** and highly efficient. A single step involves:
    1.  **Predictor Step:** Calculate a derivative `d_i` at the current point `x_i` and take a simple Euler step to a temporary point `x_hat`.
    2.  **Corrector Step:** Calculate a second derivative `d_hat` at the temporary point `x_hat`.
    3.  **Final Update:** Combine the two derivatives to take a much more accurate step to `x_{i+1}`.
    $$
    x_{i+1} = x_i + \frac{1}{2} (d_i + d_{\text{hat}}) \cdot (\sigma_{i+1} - \sigma_i)
    $$
    Notice the absence of an explicit random term `z`.

| Reverse Process | DDPM | EDM |
| :--- | :--- | :--- |
| **Training Model** | Simple U-Net `ϵ_θ(x_t, t)` conditioned on discrete `t`. | Preconditioned denoiser `D(x; σ)` conditioned on continuous `σ`. |
| **Sampling Logic** | Stochastic ancestral sampling (1st-order). | Solving an ODE (typically 2nd-order Heun). |
| **Determinism** | Inherently **stochastic**. | Inherently **deterministic** (but can be made stochastic). |
| **Speed/Steps** | Slow, requires many steps (`T`=1000+). | Fast, requires few steps (`N`=20-80). |

---

## A Practical Guide: Choosing Your Parameters in the EDM Era

The EDM framework gives you more control. Here’s a quick guide to its modern toolkit:

* **The Solver:** Start with the **deterministic Heun solver**. It offers the best balance of speed, quality, and reproducibility.
* **Number of Steps (`N`):** This is a direct trade-off between quality and speed. For fast previews, try `N = 20-25`. For high quality, `N = 40-80` is often sufficient.
* **The Timestep Schedule (`ρ`):** This parameter controls step distribution. `ρ = 7` is an excellent default, as it concentrates steps at low `σ` values, which is crucial for fine details.
* **Stochasticity (`S_churn`, `S_noise`):** These control randomness. Start with `S_churn = 0` (fully deterministic). Only introduce churn for advanced fine-tuning or troubleshooting.

By understanding these principles, you can see how diffusion models evolved from a fascinating academic curiosity into the robust, efficient, and high-quality image generation powerhouses they are today.

This video offers an excellent visualization of Score-Based Models, which provides a great intuition for how different approaches like DDPM and EDM are connected through the underlying mathematics.
[Diffusion Models From Scratch | Score-Based Generative Models Explained](https://www.youtube.com/watch?v=B4oHJpEJBAA)
http://googleusercontent.com/youtube_content/2

*Written on July 2, 2025*
